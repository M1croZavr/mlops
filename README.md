# MLOps project

## Модели машинного обучения
**Классификаторы, обучемаемые на наборах данных из изображений с разметкой**
* Персептрон с 3-мя скрытыми слоями
* Сверточная модель с 4-мя сверточными слоями и 2-мя пулинг слоями

## Структура tar.gz архива для передачи данных для обучения модели (ENDPOINT /load_data):
    ├── dataset_folder_name/  # Корень архива (он же идентификатор/имя датасета)
    │   ├── train/            # Тренировочный сплит
    │   │   ├── targets.pkl   # Pickle файл словаря вида: {image_name: label, ...}
    │   │   └── images/       # Набор изображений любого PIL-читаемого формата (image_name.jpg, image_name.png, ...)
    │   └── validation/       # Валидационный сплит
    │       ├── targets.pkl
    │       └── images/

## REST API сервис
* Загрузка архива данных в s3 объектное хранилище для дальнейшего обучения и валидации моделей
* Обучение моделей с заданными гиперпараметрами и сохранение артефактов в s3 объектное хранилище
* Выдача списка доступных классов моделей
* Выдача списка наименований обученных моделей (чекпойнтов)
* Выдача по выбранной модели результата по переданному в запросе изображению (inference)
* Удаление обученных моделей (чекпойнтов)
* Проверка статуса сервиса (healtcheck)

## Для использования REST API сервиса
1. `git clone https://github.com/M1croZavr/mlops.git`
2. Перейти в корень проекта
3. `docker-compose up -d --build`
4. REST API сервис доступен на хосте по адресу http://127.0.0.1:8000
5. Для Swagger UI перейти http://127.0.0.1:8000/docs
6. Загрузить по post запросу в `/load_data` архив из `./data/MNIST.tar.gz`
7. Загрузить по post запросу в `/load_data` архив из `./data/CIFAR10.tar.gz`
8. Загрузить архив со своими данными по желанию
9. Обучить модель по post запросу в `/fit/perceptron` или `/fit/cnn`, передав название для сохраняемого чекпойнта модели и имя датасета, на котором будет обучаться модель
10. Получить прогнозы для чекпойнта по названию модели, имени датасета и переданному изображению в /predict/{model_filename}
11. MINIO панель доступна на хосте по адресу http://127.0.0.1:9001; Логин и пароль из .env файла

## Для использования Streamlit сервиса
1. В другом терминале прописать: `poetry run streamlit run src/frontend/streamlit_app.py `
2. Следовать шагам в открывшейся странице браузера

## Для версионированния данных при помощи DVC
1. После поднятия сервера MINIO при помощи `docker-compose up -d --build` для инициализации dvc 
и определения бакета sources в качестве удаленного хранилища запускаем в консоли `bash dvc_init.sh`
2. Для отслежиания версии данных: `bash versionate_data.sh <file_or_dir_path> <dataset_name> <version>`, где
file_or_dir_path - путь к файлу/архиву с данными
dataset_name - название, которое хотите дать датасету для отслеживания
version - номер версии датасета
Скрипт добавляет данные в хранилище и коммитит в git
3. Для выбора старой версии датасета сначала ищем коммит при помощи: `git log --grep="^data vers:"`
(Все коммиты при помощи п.2 начинаются с "data vers:")
А затем `git checkout <commit_id>` + `dvc pull` 

___Состав команды:___ Исаев Артём, Лашуков Тимофей, Турыгин Дмитрий
